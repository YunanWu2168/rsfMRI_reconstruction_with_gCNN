{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1573,
     "status": "ok",
     "timestamp": 1587783935152,
     "user": {
      "displayName": "Pierre Besson",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjsjJTjx005_2UQYExcZ9CVu8Atj0_UN1VGKPsHgg=s64",
      "userId": "17266492722066909081"
     },
     "user_tz": 300
    },
    "id": "S7ZbxgsvjCiw",
    "outputId": "f24e8d03-1713-4750-ca38-b78c82d5d258"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount=True)\n",
    "# GD = \"/content/drive/My Drive/DeepLearning/\"\n",
    "# import sys\n",
    "# sys.path.append(GD + 'code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.sparse import block_diag as sparse_block_diag\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from utils.labels_preprocessing import load_labels\n",
    "from utils.load_synced_inputs import load_inputs, load_fmri\n",
    "from utils.load_graphs import load_graph\n",
    "from cnn_graph.resnetgraph import cgcnn\n",
    "from cnn_graph import graph\n",
    "import tensorflow.keras.backend as K\n",
    "from new_utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fmri preprocess\n",
    "\n",
    "fmri_subcortical_dir = '../Subcortical_fmri'\n",
    "# fmri_subcortical_dir = 'C:/Users/YuNan/Downloads/auto_encoder_try/data/Subcortical_fmri'\n",
    "assert len(os.listdir(fmri_subcortical_dir)) == len(set(os.listdir(fmri_subcortical_dir)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<14848x14848 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 103768 stored elements in Compressed Sparse Row format>, <7424x7424 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 51800 stored elements in Compressed Sparse Row format>, <3712x3712 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 25816 stored elements in Compressed Sparse Row format>, <1856x1856 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 12824 stored elements in Compressed Sparse Row format>, <928x928 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 6328 stored elements in Compressed Sparse Row format>, <464x464 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 3080 stored elements in Compressed Sparse Row format>, <232x232 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 1456 stored elements in Compressed Sparse Row format>, <116x116 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 648 stored elements in Compressed Sparse Row format>]\n"
     ]
    }
   ],
   "source": [
    "home = f\"{os.getcwd()}/..\"\n",
    "\n",
    "graphs_dir = \"../Graphs/\"            # directory containing necessary graphs\n",
    "# print(graphs_dir)\n",
    "# cortical_dir = f\"{home}/Cortical\"         # cortical node data for each subject\n",
    "# subcortical_dir = f\"{home}/SubCortical\"   # subcortical node data for each subject\n",
    "# cortical_dir = 'C:/Users/YuNan/Downloads/auto_encoder_try/data/Cortex'\n",
    "subcortical_dir = '../Subcortical'\n",
    "\n",
    "# for scan in os.listdir(cortical_dir):\n",
    "#     print (f\"{scan[:-11]}_Subcortical\")\n",
    "#     assert os.path.isfile(f\"{subcortical_dir}/{scan[:-11]}_Subcortical.mat\")\n",
    "\n",
    "assert len(os.listdir(subcortical_dir)) == len(set(os.listdir(subcortical_dir)))\n",
    "\n",
    "# L = {'cortical': load_graph(graphs_folder=graphs_dir, prefix='M_w')}\n",
    "# # print(L)\n",
    "# L['cortical'] = [graph.laplacian(A) for A in L['cortical']]\n",
    "# # print(L['cortical'])\n",
    "\n",
    "L = {'subcortical' : load_graph(graphs_folder=graphs_dir, prefix='M_sc_w')}\n",
    "L['subcortical'] = [graph.laplacian(A) for A in L['subcortical']]\n",
    "print(L['subcortical'])\n",
    "\n",
    "# # Block Diagonalize the Cortical & Subcortical Laplacians at Each Level of Coarsening\n",
    "new_L = []\n",
    "for A in zip(L[f\"subcortical\"]):\n",
    "    new_L.append( sparse_block_diag((A)) )\n",
    "L = new_L\n",
    "# print(L)\n",
    "del new_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<14848x14848 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 103768 stored elements in Compressed Sparse Row format>,\n",
       " <7424x7424 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 51800 stored elements in Compressed Sparse Row format>,\n",
       " <3712x3712 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 25816 stored elements in Compressed Sparse Row format>,\n",
       " <1856x1856 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 12824 stored elements in Compressed Sparse Row format>,\n",
       " <928x928 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 6328 stored elements in Compressed Sparse Row format>,\n",
       " <464x464 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 3080 stored elements in Compressed Sparse Row format>,\n",
       " <232x232 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 1456 stored elements in Compressed Sparse Row format>,\n",
       " <116x116 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 648 stored elements in Compressed Sparse Row format>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000102_20252_2_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000710_20252_2_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000742_20252_2_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001275_20252_2_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001693_20252_2_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1030712_20252_2_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1030841_20252_2_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>1030960_20252_2_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1031057_20252_2_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1031135_20252_2_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Subject\n",
       "0    1000102_20252_2_0\n",
       "1    1000710_20252_2_0\n",
       "2    1000742_20252_2_0\n",
       "3    1001275_20252_2_0\n",
       "4    1001693_20252_2_0\n",
       "..                 ...\n",
       "190  1030712_20252_2_0\n",
       "191  1030841_20252_2_0\n",
       "192  1030960_20252_2_0\n",
       "193  1031057_20252_2_0\n",
       "194  1031135_20252_2_0\n",
       "\n",
       "[195 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset \n",
    "import pandas as pd\n",
    "Path = '../data.csv'\n",
    "df = pd.read_csv(Path)\n",
    "filenames = df['Subject'].astype('str').to_numpy()\n",
    "# print(filenames)\n",
    "filenames2 = (filenames + '_Subcortical' +'.mat').tolist()\n",
    "# print(filenames2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subcortical\t(Samples, Nodes, Feat.):\t(195, 14848, 490)\n"
     ]
    }
   ],
   "source": [
    "# fmri \n",
    "graph_type = {'subcortical':{'path':fmri_subcortical_dir, \n",
    "                             'halves':False}\n",
    "}\n",
    "\n",
    "\n",
    "X = load_fmri(graph_type=graph_type, filenames = filenames2)\n",
    "\n",
    "sub_graphs = list(graph_type.keys())\n",
    "assert sub_graphs == ['subcortical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try\n",
    "X_try = {}\n",
    "X_try['subcortical'] = X['subcortical'][:100,:,10:]\n",
    "del X\n",
    "# X_try['subcortical'] = X['subcortical'][:,:,0:200]\n",
    "X_try['subcortical'].shape\n",
    "X = X_try\n",
    "del X_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 14848, 480)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['subcortical'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 14848, 480)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(X['subcortical'].shape[0]):\n",
    "    nodes = X['subcortical'][i].flatten()\n",
    "    X_mean = np.mean(nodes)\n",
    "    X_std = np.std(nodes)\n",
    "    X['subcortical'][i] = (X['subcortical'][i] - X_mean) / X_std\n",
    "    \n",
    "del nodes   \n",
    "all_nodes = np.concatenate([X[sub].flatten() for sub in sub_graphs])\n",
    "del all_nodes\n",
    "\n",
    "new_X = []\n",
    "for A in zip(X[f\"subcortical\"]):\n",
    "    new_X.append(np.concatenate((A), axis = 0))\n",
    "    \n",
    "X = np.concatenate([np.expand_dims(i, axis=0) for i in new_X], axis=0).astype('float32')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 14848, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split with time point\n",
    "new_X = []\n",
    "# bb.T.reshape()\n",
    "for i in range(X.shape[0]):\n",
    "    new_X.append(X[i,:,:].T)\n",
    "new_XX = np.concatenate([np.expand_dims(i, axis=0) for i in new_X], axis=0).astype('float32')\n",
    "X_re = np.reshape(new_XX, (X.shape[0]* X.shape[2], X.shape[1], 1))\n",
    "del X\n",
    "X_re.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del new_XX\n",
    "X_re2 = np.reshape(X_re, (8000,6,14848,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 6, 14848, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_re2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "goQRb1A3jY5y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 6, 14848, 1) (1600, 6, 14848, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test = X_re2[:8*800,:,:,:], X_re2[8*800:,:,:,:]\n",
    "# X_ttest = X_re[39000:,:,:]\n",
    "del X_re\n",
    "del X_re2\n",
    "print(X_train.shape, X_test.shape)\n",
    "batch_size = 4\n",
    "\n",
    "train_generator = utils.DataGenerator2(X_train, \n",
    "                                      batch_size = batch_size, \n",
    "                                      shuffle=True, \n",
    "                                      force_balance=False, \n",
    "                                      do_augmentation = False, \n",
    "#                                       tta=10, \n",
    "#                                       aug_params=aug_training,\n",
    "                                      auto_encoder=True)\n",
    "test_generator  = utils.DataGenerator2(X_test,  \n",
    "                                      batch_size = batch_size, \n",
    "                                      shuffle=False, \n",
    "                                      force_balance=False, \n",
    "                                      do_augmentation = False, \n",
    "#                                       tta=10, \n",
    "#                                       aug_params=aug_testing,\n",
    "                                      auto_encoder=True)\n",
    "\n",
    "# ttest_generator  = utils.DataGenerator(X_ttest,  \n",
    "#                                       batch_size = 1, \n",
    "#                                       shuffle=False, \n",
    "#                                       force_balance=False, \n",
    "#                                       do_augmentation = False, \n",
    "# #                                       tta=10, \n",
    "# #                                       aug_params=aug_testing,\n",
    "#                                       auto_encoder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_generator))\n",
    "len(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C4o5Wr64kf7C"
   },
   "source": [
    "## Architecture of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 6, 14848, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 6, 14848, 32) 128         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 6, 14848, 32) 3104        time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 6, 14848, 32) 128         time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 6, 14848, 32) 0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 6, 14848, 32) 3072        time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 6, 14848, 32) 128         time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 6, 14848, 32) 0           time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 6, 7424, 32)  0           time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 6, 7424, 32)  3104        time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 6, 7424, 32)  128         time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, 6, 7424, 32)  0           time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, 6, 7424, 32)  3072        time_distributed_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, 6, 7424, 32)  128         time_distributed_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistri (None, 6, 7424, 32)  0           time_distributed_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistri (None, 6, 7424, 32)  3104        time_distributed_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_15 (TimeDistri (None, 6, 7424, 32)  128         time_distributed_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_16 (TimeDistri (None, 6, 7424, 32)  0           time_distributed_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_17 (TimeDistri (None, 6, 7424, 32)  3072        time_distributed_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_18 (TimeDistri (None, 6, 7424, 32)  128         time_distributed_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_19 (TimeDistri (None, 6, 7424, 32)  0           time_distributed_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_20 (TimeDistri (None, 6, 3712, 32)  0           time_distributed_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_21 (TimeDistri (None, 6, 3712, 32)  3104        time_distributed_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_22 (TimeDistri (None, 6, 3712, 32)  128         time_distributed_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_23 (TimeDistri (None, 6, 3712, 32)  0           time_distributed_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_24 (TimeDistri (None, 6, 3712, 32)  3072        time_distributed_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_25 (TimeDistri (None, 6, 3712, 32)  128         time_distributed_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_26 (TimeDistri (None, 6, 3712, 32)  0           time_distributed_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_27 (TimeDistri (None, 6, 3712, 32)  3104        time_distributed_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_28 (TimeDistri (None, 6, 3712, 32)  128         time_distributed_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_29 (TimeDistri (None, 6, 3712, 32)  0           time_distributed_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_30 (TimeDistri (None, 6, 3712, 32)  3072        time_distributed_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_31 (TimeDistri (None, 6, 3712, 32)  128         time_distributed_30[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_32 (TimeDistri (None, 6, 3712, 32)  0           time_distributed_31[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_33 (TimeDistri (None, 6, 1856, 32)  0           time_distributed_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_34 (TimeDistri (None, 6, 1856, 32)  3104        time_distributed_33[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_35 (TimeDistri (None, 6, 1856, 32)  128         time_distributed_34[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_36 (TimeDistri (None, 6, 1856, 32)  0           time_distributed_35[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_37 (TimeDistri (None, 6, 1856, 32)  3072        time_distributed_36[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_38 (TimeDistri (None, 6, 1856, 32)  128         time_distributed_37[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_39 (TimeDistri (None, 6, 1856, 32)  0           time_distributed_38[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_40 (TimeDistri (None, 6, 1856, 32)  3104        time_distributed_39[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_41 (TimeDistri (None, 6, 1856, 32)  128         time_distributed_40[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_42 (TimeDistri (None, 6, 1856, 32)  0           time_distributed_41[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_43 (TimeDistri (None, 6, 1856, 32)  3072        time_distributed_42[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_44 (TimeDistri (None, 6, 1856, 32)  128         time_distributed_43[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_45 (TimeDistri (None, 6, 1856, 32)  0           time_distributed_44[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_46 (TimeDistri (None, 6, 928, 32)   0           time_distributed_45[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_47 (TimeDistri (None, 6, 928, 32)   3104        time_distributed_46[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_48 (TimeDistri (None, 6, 928, 32)   128         time_distributed_47[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_49 (TimeDistri (None, 6, 928, 32)   0           time_distributed_48[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_50 (TimeDistri (None, 6, 928, 32)   3072        time_distributed_49[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_51 (TimeDistri (None, 6, 928, 32)   128         time_distributed_50[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_52 (TimeDistri (None, 6, 928, 32)   0           time_distributed_51[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_53 (TimeDistri (None, 6, 928, 32)   3104        time_distributed_52[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_54 (TimeDistri (None, 6, 928, 32)   128         time_distributed_53[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_55 (TimeDistri (None, 6, 928, 32)   0           time_distributed_54[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_56 (TimeDistri (None, 6, 928, 32)   3072        time_distributed_55[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_57 (TimeDistri (None, 6, 928, 32)   128         time_distributed_56[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_58 (TimeDistri (None, 6, 928, 32)   0           time_distributed_57[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_59 (TimeDistri (None, 6, 464, 32)   0           time_distributed_58[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_60 (TimeDistri (None, 6, 464, 32)   3104        time_distributed_59[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_61 (TimeDistri (None, 6, 464, 32)   128         time_distributed_60[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_62 (TimeDistri (None, 6, 464, 32)   0           time_distributed_61[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_63 (TimeDistri (None, 6, 464, 32)   3072        time_distributed_62[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_64 (TimeDistri (None, 6, 464, 32)   128         time_distributed_63[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_65 (TimeDistri (None, 6, 464, 32)   0           time_distributed_64[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_66 (TimeDistri (None, 6, 464, 32)   3104        time_distributed_65[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_67 (TimeDistri (None, 6, 464, 32)   128         time_distributed_66[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_68 (TimeDistri (None, 6, 464, 32)   0           time_distributed_67[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_69 (TimeDistri (None, 6, 464, 32)   3072        time_distributed_68[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_70 (TimeDistri (None, 6, 464, 32)   128         time_distributed_69[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_71 (TimeDistri (None, 6, 464, 32)   0           time_distributed_70[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_72 (TimeDistri (None, 6, 232, 32)   0           time_distributed_71[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_73 (TimeDistri (None, 6, 232, 32)   3104        time_distributed_72[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_74 (TimeDistri (None, 6, 232, 32)   128         time_distributed_73[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_75 (TimeDistri (None, 6, 232, 32)   0           time_distributed_74[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_76 (TimeDistri (None, 6, 232, 32)   3072        time_distributed_75[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_77 (TimeDistri (None, 6, 232, 32)   128         time_distributed_76[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_78 (TimeDistri (None, 6, 232, 32)   0           time_distributed_77[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_79 (TimeDistri (None, 6, 232, 32)   3104        time_distributed_78[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_80 (TimeDistri (None, 6, 232, 32)   128         time_distributed_79[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_81 (TimeDistri (None, 6, 232, 32)   0           time_distributed_80[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_82 (TimeDistri (None, 6, 232, 32)   3072        time_distributed_81[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_83 (TimeDistri (None, 6, 232, 32)   128         time_distributed_82[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_84 (TimeDistri (None, 6, 232, 32)   0           time_distributed_83[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_85 (TimeDistri (None, 6, 116, 32)   0           time_distributed_84[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_86 (TimeDistri (None, 6, 3712)      0           time_distributed_85[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 6, 256)       4064256     time_distributed_86[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_87 (TimeDistri (None, 6, 256)       65792       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_88 (TimeDistri (None, 6, 256)       65792       lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (Lambda)         (None, 6, 256)       0           time_distributed_87[0][0]        \n",
      "                                                                 time_distributed_88[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 4,279,584\n",
      "Trainable params: 4,277,920\n",
      "Non-trainable params: 1,664\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 6, 256)]          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_89 (TimeDis (None, 6, 3712)           953984    \n",
      "_________________________________________________________________\n",
      "time_distributed_90 (TimeDis (None, 6, 116, 32)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_91 (TimeDis (None, 6, 116, 32)        3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_92 (TimeDis (None, 6, 116, 32)        128       \n",
      "_________________________________________________________________\n",
      "time_distributed_93 (TimeDis (None, 6, 116, 32)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_94 (TimeDis (None, 6, 116, 32)        3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_95 (TimeDis (None, 6, 116, 32)        128       \n",
      "_________________________________________________________________\n",
      "time_distributed_96 (TimeDis (None, 6, 116, 32)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_97 (TimeDis (None, 6, 116, 32)        3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_98 (TimeDis (None, 6, 116, 32)        128       \n",
      "_________________________________________________________________\n",
      "time_distributed_99 (TimeDis (None, 6, 116, 32)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_100 (TimeDi (None, 6, 116, 32)        3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_101 (TimeDi (None, 6, 116, 32)        128       \n",
      "_________________________________________________________________\n",
      "time_distributed_102 (TimeDi (None, 6, 116, 32)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_103 (TimeDi (None, 6, 232, 32)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_104 (TimeDi (None, 6, 232, 32)        3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_105 (TimeDi (None, 6, 232, 32)        128       \n",
      "_________________________________________________________________\n",
      "time_distributed_106 (TimeDi (None, 6, 232, 32)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_107 (TimeDi (None, 6, 232, 32)        3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_108 (TimeDi (None, 6, 232, 32)        128       \n",
      "_________________________________________________________________\n",
      "time_distributed_109 (TimeDi (None, 6, 232, 32)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_110 (TimeDi (None, 6, 232, 32)        3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_111 (TimeDi (None, 6, 232, 32)        128       \n",
      "_________________________________________________________________\n",
      "time_distributed_112 (TimeDi (None, 6, 232, 32)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_113 (TimeDi (None, 6, 232, 32)        3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_114 (TimeDi (None, 6, 232, 32)        128       \n",
      "_________________________________________________________________\n",
      "time_distributed_115 (TimeDi (None, 6, 232, 32)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_116 (TimeDi (None, 6, 464, 32)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_117 (TimeDi (None, 6, 464, 32)        3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_118 (TimeDi (None, 6, 464, 32)        128       \n",
      "_________________________________________________________________\n",
      "time_distributed_119 (TimeDi (None, 6, 464, 32)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_120 (TimeDi (None, 6, 464, 32)        3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_121 (TimeDi (None, 6, 464, 32)        128       \n",
      "_________________________________________________________________\n",
      "time_distributed_122 (TimeDi (None, 6, 464, 32)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_123 (TimeDi (None, 6, 464, 32)        3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_124 (TimeDi (None, 6, 464, 32)        128       \n",
      "_________________________________________________________________\n",
      "time_distributed_125 (TimeDi (None, 6, 464, 32)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_126 (TimeDi (None, 6, 464, 32)        3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_127 (TimeDi (None, 6, 464, 32)        128       \n",
      "_________________________________________________________________\n",
      "time_distributed_128 (TimeDi (None, 6, 464, 32)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_129 (TimeDi (None, 6, 928, 32)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_130 (TimeDi (None, 6, 928, 32)        3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_131 (TimeDi (None, 6, 928, 32)        128       \n",
      "_________________________________________________________________\n",
      "time_distributed_132 (TimeDi (None, 6, 928, 32)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_133 (TimeDi (None, 6, 928, 32)        3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_134 (TimeDi (None, 6, 928, 32)        128       \n",
      "_________________________________________________________________\n",
      "time_distributed_135 (TimeDi (None, 6, 928, 32)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_136 (TimeDi (None, 6, 928, 32)        3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_137 (TimeDi (None, 6, 928, 32)        128       \n",
      "_________________________________________________________________\n",
      "time_distributed_138 (TimeDi (None, 6, 928, 32)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_139 (TimeDi (None, 6, 928, 32)        3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_140 (TimeDi (None, 6, 928, 32)        128       \n",
      "_________________________________________________________________\n",
      "time_distributed_141 (TimeDi (None, 6, 928, 32)        0         \n",
      "_________________________________________________________________\n",
      "time_distributed_142 (TimeDi (None, 6, 1856, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_143 (TimeDi (None, 6, 1856, 32)       3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_144 (TimeDi (None, 6, 1856, 32)       128       \n",
      "_________________________________________________________________\n",
      "time_distributed_145 (TimeDi (None, 6, 1856, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_146 (TimeDi (None, 6, 1856, 32)       3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_147 (TimeDi (None, 6, 1856, 32)       128       \n",
      "_________________________________________________________________\n",
      "time_distributed_148 (TimeDi (None, 6, 1856, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_149 (TimeDi (None, 6, 1856, 32)       3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_150 (TimeDi (None, 6, 1856, 32)       128       \n",
      "_________________________________________________________________\n",
      "time_distributed_151 (TimeDi (None, 6, 1856, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_152 (TimeDi (None, 6, 1856, 32)       3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_153 (TimeDi (None, 6, 1856, 32)       128       \n",
      "_________________________________________________________________\n",
      "time_distributed_154 (TimeDi (None, 6, 1856, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_155 (TimeDi (None, 6, 3712, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_156 (TimeDi (None, 6, 3712, 32)       3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_157 (TimeDi (None, 6, 3712, 32)       128       \n",
      "_________________________________________________________________\n",
      "time_distributed_158 (TimeDi (None, 6, 3712, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_159 (TimeDi (None, 6, 3712, 32)       3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_160 (TimeDi (None, 6, 3712, 32)       128       \n",
      "_________________________________________________________________\n",
      "time_distributed_161 (TimeDi (None, 6, 3712, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_162 (TimeDi (None, 6, 3712, 32)       3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_163 (TimeDi (None, 6, 3712, 32)       128       \n",
      "_________________________________________________________________\n",
      "time_distributed_164 (TimeDi (None, 6, 3712, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_165 (TimeDi (None, 6, 3712, 32)       3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_166 (TimeDi (None, 6, 3712, 32)       128       \n",
      "_________________________________________________________________\n",
      "time_distributed_167 (TimeDi (None, 6, 3712, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_168 (TimeDi (None, 6, 7424, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_169 (TimeDi (None, 6, 7424, 32)       3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_170 (TimeDi (None, 6, 7424, 32)       128       \n",
      "_________________________________________________________________\n",
      "time_distributed_171 (TimeDi (None, 6, 7424, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_172 (TimeDi (None, 6, 7424, 32)       3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_173 (TimeDi (None, 6, 7424, 32)       128       \n",
      "_________________________________________________________________\n",
      "time_distributed_174 (TimeDi (None, 6, 7424, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_175 (TimeDi (None, 6, 7424, 32)       3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_176 (TimeDi (None, 6, 7424, 32)       128       \n",
      "_________________________________________________________________\n",
      "time_distributed_177 (TimeDi (None, 6, 7424, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_178 (TimeDi (None, 6, 7424, 32)       3072      \n",
      "_________________________________________________________________\n",
      "time_distributed_179 (TimeDi (None, 6, 7424, 32)       128       \n",
      "_________________________________________________________________\n",
      "time_distributed_180 (TimeDi (None, 6, 7424, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_181 (TimeDi (None, 6, 14848, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_182 (TimeDi (None, 6, 14848, 1)       96        \n",
      "=================================================================\n",
      "Total params: 1,043,680\n",
      "Trainable params: 1,041,888\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vae\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 6, 14848, 1)]     0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 6, 256), (None, 6 4279584   \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 6, 14848, 1)       1043680   \n",
      "=================================================================\n",
      "Total params: 5,323,264\n",
      "Trainable params: 5,319,808\n",
      "Non-trainable params: 3,456\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, GRU, GlobalAveragePooling1D, \n",
    "    GlobalAveragePooling2D, TimeDistributed, \n",
    "    concatenate, Masking, Bidirectional\n",
    ")\n",
    "encoder_inputs = keras.Input(shape=(6,14848,1))\n",
    "latent_dim = 256\n",
    "Depth = 7\n",
    "n_filter = 32\n",
    "\n",
    "for B in range(Depth):\n",
    "    for F in range(2):\n",
    "        if B == 0 and F == 0:\n",
    "            x1 = TimeDistributed(utils.ChebLayer(L[B],3,n_filter,use_bias=True,kernel_regularizer=keras.regularizers.l2(5e-5)))(encoder_inputs)\n",
    "        else:\n",
    "            x1 = TimeDistributed(utils.ChebLayer(L[B],3,n_filter,use_bias=True,kernel_regularizer=keras.regularizers.l2(5e-5)))(x1)\n",
    "            x1 = TimeDistributed(keras.layers.BatchNormalization())(x1)\n",
    "            x1 = TimeDistributed(keras.layers.Activation('elu'))(x1)\n",
    "            x1 = TimeDistributed(utils.ChebLayer(L[B],3,n_filter,use_bias=False,kernel_regularizer=keras.regularizers.l2(5e-5)))(x1)\n",
    "            x1 = TimeDistributed(keras.layers.BatchNormalization())(x1)\n",
    "            x1 = TimeDistributed(keras.layers.Activation('elu'))(x1)\n",
    "    x1 = TimeDistributed(keras.layers.MaxPooling1D(2))(x1)\n",
    "x =  TimeDistributed(layers.Flatten())(x1)\n",
    "        \n",
    "x = LSTM(units=256, activation='elu', kernel_initializer='glorot_uniform', unit_forget_bias=True, dropout=0.3, return_sequences = True)(x)\n",
    "z_mean = TimeDistributed(layers.Dense(latent_dim, name = 'z_mean'))(x)\n",
    "z_log_var = TimeDistributed(layers.Dense(latent_dim, name = 'z_log_var'))(x)\n",
    "#         print(z_mean.shape)\n",
    "#         print(z_log_var[2][2])\n",
    "        \n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=K.shape(z_mean), mean=0., stddev=1.) \n",
    "    return z_mean + K.exp(z_log_var/2)*epsilon \n",
    "z = layers.Lambda(sampling, name='encoder_output')([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()\n",
    "\n",
    "\n",
    "# Decoder ResNet Blocks\n",
    "latent_inputs = keras.Input(shape=(6,latent_dim,))\n",
    "x = TimeDistributed(layers.Dense(3712))(latent_inputs)\n",
    "x = TimeDistributed(layers.Reshape((116, 32)))(x)\n",
    "# print(x.shape)\n",
    "for B in range(Depth):\n",
    "    for F in range(2):\n",
    "        #print(L[Depth - B].shape)\n",
    "        if B == 0 and F == 0:\n",
    "            x1 = TimeDistributed(utils.ChebLayer(L[Depth - B],3,n_filter,use_bias=False,kernel_regularizer=keras.regularizers.l2(5e-5)))(x)\n",
    "        else:\n",
    "            x1 = TimeDistributed(utils.ChebLayer(L[Depth - B],3,n_filter,use_bias=False,kernel_regularizer=keras.regularizers.l2(5e-5)))(x1)\n",
    "        x1 = TimeDistributed(keras.layers.BatchNormalization())(x1)\n",
    "        x1 = TimeDistributed(keras.layers.Activation('elu'))(x1)\n",
    "        x1 = TimeDistributed(utils.ChebLayer(L[Depth - B],3,n_filter,use_bias=False,kernel_regularizer=keras.regularizers.l2(5e-5)))(x1)\n",
    "        x1 = TimeDistributed(keras.layers.BatchNormalization())(x1)\n",
    "        x1 = TimeDistributed(keras.layers.Activation('elu'))(x1)\n",
    "    x1 = TimeDistributed(keras.layers.UpSampling1D(size=2))(x1)\n",
    "decoder_outputs = TimeDistributed(utils.ChebLayer(L[0],3,1,use_bias=False,kernel_regularizer=keras.regularizers.l2(5e-5)))(x1)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()\n",
    "\n",
    "# Instantiate VAE\n",
    "vae_outputs = decoder(encoder(encoder_inputs)[2])\n",
    "vae         = Model(encoder_inputs, vae_outputs, name='vae')\n",
    "vae.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 6, 14848)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "BN_0 (BatchNormalization)       (None, 6, 14848)     59392       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Percep_0 (Conv1D)               (None, 6, 128)       5701632     BN_0[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 6, 128)       0           Percep_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Percep_1 (Conv1D)               (None, 6, 128)       49152       leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 6, 128)       0           Percep_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Neg (TensorFlowOpLa [(None, 6, 128)]     0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 6, 128)       0           Percep_0[0][0]                   \n",
      "                                                                 tf_op_layer_Neg[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 3, 128)       0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "Percep_2 (Conv1D)               (None, 3, 128)       49152       max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 3, 128)       0           Percep_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Percep_3 (Conv1D)               (None, 3, 128)       49152       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 3, 128)       0           Percep_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Neg_1 (TensorFlowOp [(None, 3, 128)]     0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 3, 128)       0           Percep_2[0][0]                   \n",
      "                                                                 tf_op_layer_Neg_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 3, 128)       0           add_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 5,908,480\n",
      "Trainable params: 5,878,784\n",
      "Non-trainable params: 29,696\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#     BN_0 = keras.layers.BatchNormalization(name='BN_0')\n",
    "#     x1 = BN_0(x1)\n",
    "    #Layer_0  = utils.ChebLayer(L[0],4,16,0,use_bias=False,kernel_regularizer=keras.regularizers.l2(1e-12), name=\"Percep_0\")\n",
    "fmri_input = keras.layers.Input(shape=(encoder_inputs.shape[1], encoder_inputs.shape[2]))\n",
    "x1 = keras.layers.BatchNormalization(name='BN_0')(fmri_input)\n",
    "x1 = keras.layers.Conv1D(128, 3, padding='same', use_bias=False, kernel_initializer='glorot_uniform',\n",
    "                         kernel_regularizer=keras.regularizers.l2(1e-5), name='Percep_0')(x1)\n",
    "x11 = keras.layers.LeakyReLU()(x1)\n",
    "\n",
    "x11 = keras.layers.Conv1D(128, 3, padding='same', use_bias=False, kernel_initializer='glorot_uniform',\n",
    "                         kernel_regularizer=keras.regularizers.l2(1e-5), name='Percep_1')(x11)\n",
    "x11 = keras.layers.LeakyReLU()(x11)\n",
    "x1  = keras.layers.add([x1, -x11])\n",
    "x1  = keras.layers.MaxPooling1D()(x1)\n",
    "\n",
    "x1 = keras.layers.Conv1D(128, 3, padding='same', use_bias=False, kernel_initializer='glorot_uniform',\n",
    "                         kernel_regularizer=keras.regularizers.l2(1e-5), name='Percep_2')(x1)\n",
    "x11 = keras.layers.LeakyReLU()(x1)\n",
    "\n",
    "x11 = keras.layers.Conv1D(128, 3, padding='same', use_bias=False, kernel_initializer='glorot_uniform',\n",
    "                         kernel_regularizer=keras.regularizers.l2(1e-5), name='Percep_3')(x11)\n",
    "x11 = keras.layers.LeakyReLU()(x11)\n",
    "x1  = keras.layers.add([x1, -x11])\n",
    "per_output = keras.layers.LeakyReLU()(x1)\n",
    "\n",
    "per_network = Model(inputs=fmri_input, outputs=per_output)\n",
    "\n",
    "per_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percep_model(per_input):\n",
    "    lossModelOutputs = per_network(per_input)\n",
    "    return lossModelOutputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0002\n",
    "LOSS_FACTOR = 0.002 # 0.002\n",
    "Per_fac = 0.05  #0.05\n",
    "\n",
    "\n",
    "def r_loss(y_true, y_pred):\n",
    "    return K.mean(K.square(y_true - y_pred), axis = [1,2])\n",
    "\n",
    "def kl_loss(y_true, y_pred):\n",
    "    kl_loss =  -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis = 1)\n",
    "    return kl_loss\n",
    "\n",
    "def per_loss(y_true, y_pred):\n",
    "#     print(\"***\")\n",
    "    y_true1 = tf.squeeze(y_true, axis = -1)\n",
    "    y_pred1 = tf.squeeze(y_pred, axis = -1)\n",
    "    per_true1 = percep_model(y_true1)\n",
    "    per_pred1 = percep_model(y_pred1)\n",
    "    perc_loss = K.mean(K.square(per_true1 - per_pred1), axis=[1,2])\n",
    "    perc_loss = tf.expand_dims(perc_loss, -1)\n",
    "#     perc_loss = K.mean(perc_loss)\n",
    "    return perc_loss\n",
    "\n",
    "def total_loss(y_true, y_pred):\n",
    "    return r_loss(y_true, y_pred) + LOSS_FACTOR*kl_loss(y_true, y_pred) + Per_fac*per_loss(y_true, y_pred)\n",
    "  \n",
    "adam_optimizer = keras.optimizers.Adam(lr = LEARNING_RATE)\n",
    "\n",
    "vae.compile(optimizer=adam_optimizer, loss = total_loss, metrics = [r_loss, kl_loss, per_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vae.load_weights('C:/Users/YuNan/Downloads/auto_encoder_try/models/lstm_percep_try.hdf5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# per_network.get_layer(\"Percep_0\").trainable = False\n",
    "# per_network.get_layer(\"Percep_1\").trainable = False\n",
    "# per_network.get_layer(\"Percep_2\").trainable = False\n",
    "# per_network.get_layer(\"Percep_3\").trainable = False\n",
    "# per_network.get_layer(\"BN_0\").trainable = False\n",
    "per_network.trainable = False\n",
    "for l in per_network.layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# xx = np.ones((4,6,14848,1),dtype = 'float32')\n",
    "# yy = np.ones((4,6,14848,1), dtype = 'float32')\n",
    "# # type(xx)\n",
    "# losss = total_loss(xx,yy)\n",
    "# losss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "es = EarlyStopping(monitor='val_loss', \n",
    "                   verbose=1, \n",
    "                   patience=6, \n",
    "                   min_delta=0.0001, \n",
    "                   mode='min')\n",
    "mc = ModelCheckpoint('.../lstm_percep.hdf5', `\n",
    "                     monitor='val_loss', \n",
    "                     verbose=1, \n",
    "                     save_best_only=True, \n",
    "                     mode='min')\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                        mode='min',\n",
    "                        factor=0.1,\n",
    "                        patience=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vMyX9D3buIIM",
    "outputId": "7cedd5f0-1c86-40b1-e9d1-8b76aaa86928"
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "history = vae.fit(train_generator, validation_data=test_generator, epochs = epochs, use_multiprocessing=False, callbacks = [es, mc,rlr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot history: Categorical crossentropy & Accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label='Categorical crossentropy (training data)')\n",
    "plt.plot(history.history['val_loss'], label='Categorical crossentropy (validation data)')\n",
    "# plt.plot(history.history['acc'], label='Accuracy (training data)')\n",
    "# plt.plot(history.history['val_acc'], label='Accuracy (validation data)')\n",
    "plt.title('Model performance for 3D MNIST Keras Conv3D example')\n",
    "plt.ylabel('Loss value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMdSPYkDYl1nXjPSEKUrOVK",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "GraphAutoEncoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
